{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ecoronado/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ecoronado/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "import data_prep\n",
    "from data_prep import voca\n",
    "from data_prep import docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special class \n",
    "class DefaultDict(dict):\n",
    "    def __init__(self, v):\n",
    "        self.v = v\n",
    "        dict.__init__(self)\n",
    "    def __getitem__(self, k):\n",
    "        return dict.__getitem__(self, k) if k in self else self.v\n",
    "    def update(self, d):\n",
    "        dict.update(self, d)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing default values for start of alg\n",
    "\n",
    "# Hyperparameters (concentration parms of DP distributions)\n",
    "gamma = np.random.gamma(1, 1)\n",
    "alpha = np.random.gamma(1, 1)\n",
    "beta = .5\n",
    "\n",
    "# size of vocabulary \n",
    "V = voca.size()\n",
    "# To see words type voca.vocas\n",
    "\n",
    "# Number of documents \n",
    "M = len(docs)\n",
    "\n",
    "# Table index for document j\n",
    "using_t = [[0] for j in range(M)]\n",
    "\n",
    "# Dish index - 0 means draw a new topic \n",
    "k = 0\n",
    "using_k = [0]\n",
    "\n",
    "\n",
    "# x is data, t is table index, k is topic index, n is number of terms, m is number of tables\n",
    "\n",
    "# Vocabulary for each doc-term - this is the input data and doesn't change \n",
    "x_ji = docs\n",
    "\n",
    "# Topics of document and table\n",
    "k_jt = [np.zeros(1 ,dtype=int) for j in range(M)]\n",
    "\n",
    "# Number of terms for each table of document\n",
    "n_jt = [np.zeros(1 ,dtype=int) for j in range(M)]   \n",
    "\n",
    "# Number of terms for each table and vocabulary of document \n",
    "n_jtv = [[None] for j in range(M)]\n",
    "\n",
    "\n",
    "m = 0\n",
    "# Number of tables for each topic\n",
    "m_k = np.ones(1 ,dtype=int)  \n",
    "\n",
    "# Number of terms for each topic ( + beta * V )\n",
    "n_k = np.array([beta * V]) \n",
    "\n",
    "# Number of terms for each topic and vocabulary ( + beta )\n",
    "n_kv = [DefaultDict(0)]            \n",
    "\n",
    "# Table for each document and term (-1 means not-assigned)\n",
    "t_ji = [np.zeros(len(x_i), dtype=int) - 1 for x_i in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helpers ## \n",
    "\n",
    "# Function that takes v (term index) and returns a list that represents the distribution of a term across topics -- i.e. each element is the proportion of terms in topic k that are term v \n",
    "def calc_f_k(v):\n",
    "    return [n_kv[v] for n_kv in n_kv]/n_k\n",
    "\n",
    "\n",
    "# Function that calculates the posterior distribution of tables for doc j / arguments: j - doc index,f_k - distribution of term across topics \n",
    "\n",
    "def calc_table_posterior(j, f_k, using_t, n_jt):\n",
    "    \n",
    "    # Store list of tables for doc j as using_t\n",
    "    using_t = using_t[j]\n",
    "    \n",
    "    # Number of terms in doc j at each table times disibutrion of terms across topics ## CHECK THIS \n",
    "    p_t = n_jt[j][using_t] * f_k[k_jt[j][using_t]]\n",
    "    \n",
    "    # Sum of number of tables across topics weighted by f_k + gamma/(vocab size) -- this corresponds with the probability of selecting a new table \n",
    "    p_x_ji = np.inner(m_k, f_k) + gamma / V\n",
    "    \n",
    "    # Storing probability of new table as first element \n",
    "    p_t[0] = p_x_ji * alpha / (gamma + m)\n",
    "\n",
    "    # Return likelihood over prior \n",
    "    return p_t / p_t.sum()\n",
    "\n",
    "\n",
    "def calc_dish_posterior_w(f_k):\n",
    "    \"calculate dish(topic) posterior when one word is removed\"\n",
    "    \n",
    "    p_k = (m_k * f_k)[using_k]\n",
    "    p_k[0] = gamma / V\n",
    "    \n",
    "    return p_k / p_k.sum()\n",
    "    \n",
    "    \n",
    "def calc_dish_posterior_t(j, t, n_k, n_jt, n_jtv):\n",
    "    \"calculate dish(topic) posterior when one table is removed\"\n",
    "    k_old = k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "    \n",
    "    Vbeta = V * beta\n",
    "    n_k = n_k.copy()\n",
    "    n_jt2 = n_jt.copy()[j][t]\n",
    "    n_k[k_old] -= n_jt2\n",
    "    n_k = n_k[using_k]\n",
    "    log_p_k = np.log(m_k[using_k]) + gammaln(n_k) - gammaln(n_k + n_jt2)\n",
    "    log_p_k_new = np.log(gamma) + gammaln(Vbeta) - gammaln(Vbeta + n_jt2)\n",
    "\n",
    "    gammaln_beta = gammaln(beta)\n",
    "    for w, n_jtw in n_jtv[j][t].items():\n",
    "        assert n_jtw >= 0\n",
    "        if n_jtw == 0: continue\n",
    "        n_kw = np.array([n.get(w, beta) for n in n_kv])\n",
    "        n_kw[k_old] -= n_jtw\n",
    "        n_kw = n_kw[using_k]\n",
    "        n_kw[0] = 1 # dummy for logarithm's warning\n",
    "        if np.any(n_kw <= 0): print(n_kw) # for debug\n",
    "        log_p_k += gammaln(n_kw + n_jtw) - gammaln(n_kw)\n",
    "        log_p_k_new += gammaln(beta + n_jtw) - gammaln_beta\n",
    "        \n",
    "        \n",
    "    log_p_k[0] = log_p_k_new\n",
    "    \n",
    "    p_k = np.exp(log_p_k - log_p_k.max())\n",
    "    return p_k / p_k.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HPLDA Alg ### \n",
    "\n",
    "\n",
    "# g = 25 epochs\n",
    "for g in range(25):\n",
    "    \n",
    "# Loop - sampling_t - j is doc index (e.g. first doc is 0), i is term index (0 is first element of global vocabulary voca.vocas)\n",
    "\n",
    "    # Loop through the data \n",
    "    for j, x_i in enumerate(x_ji):\n",
    "        \n",
    "        # For each doc, loop through each term\n",
    "        for i in range(len(x_i)):\n",
    "            \n",
    "            ### Reassign table for term i in document j ###\n",
    "            t = t_ji[j][i]\n",
    "            if t  > 0:\n",
    "                k = k_jt[j][t]\n",
    "                assert k > 0\n",
    "        \n",
    "                # decrease counters\n",
    "                v = x_ji[j][i]\n",
    "                n_kv[k][v] -= 1\n",
    "                n_k[k] -= 1\n",
    "                n_jt[j][t] -= 1\n",
    "                n_jtv[j][t][v] -= 1\n",
    "        \n",
    "                if n_jt[j][t] == 0:\n",
    "                    \n",
    "                    # Remove table \n",
    "                    \n",
    "                    # Set topic index at doc j and table t to k\n",
    "                    k = k_jt[j][t]\n",
    "                    \n",
    "                    # Remove t from list of tables being used in doc j\n",
    "                    using_t[j].remove(t)\n",
    "                    \n",
    "                    # Decrease number of tables for topic k by 1\n",
    "                    m_k[k] -= 1\n",
    "                    # Decrease number of tables overall (?) by 1\n",
    "                    m -= 1\n",
    "                    assert m_k[k] >= 0\n",
    "                    \n",
    "                    # If number of tables for topic k is 0 remove topic\n",
    "                    if m_k[k] == 0:\n",
    "                        using_k.remove(k)\n",
    "        \n",
    "                                    \n",
    "            # Store term index as v\n",
    "            v = x_ji[j][i]\n",
    "            \n",
    "            # Calculate the distribution of v across the topics -- f_k will be the base distribution for the calc_table_posterior function \n",
    "            f_k = calc_f_k(v)\n",
    "            assert f_k[0] == 0 # f_k[0] is a dummy and will be erased\n",
    "        \n",
    "            \n",
    "            # Calculating the posterior distribution of tables --  p(t_ji=t)\n",
    "            p_t = calc_table_posterior(j, f_k, using_t, n_jt)\n",
    "            \n",
    "            # This just prints some results while the alg runs - blocking out for now     \n",
    "            # if len(p_t) > 1 and p_t[1] < 0: dump()\n",
    "                \n",
    "            # Sample from the posterior and assigned the corresponding table index to t_new (not necessarily a new table - it's a new sample)\n",
    "            t_new = using_t[j][np.random.multinomial(1, p_t).argmax()]\n",
    "            \n",
    "            # If t_new == 0 (i.e. the table is new)\n",
    "            if t_new == 0:\n",
    "                \n",
    "                # Calculate the posterior distribution of topics \n",
    "                p_k = calc_dish_posterior_w(f_k)\n",
    "                \n",
    "                # Sample from this posterior distribution and assign the corresponding topic index to k_new \n",
    "                k_new = using_k[np.random.multinomial(1, p_k).argmax()]\n",
    "                \n",
    "                # If k_new == 0 (i.e. the topic is new)\n",
    "                if k_new == 0:\n",
    "                    \n",
    "                    # Add new dish and store as k_new \n",
    "                    for k_new, k in enumerate(using_k):\n",
    "                        if k_new != k: break\n",
    "                    else:\n",
    "                        k_new = len(using_k)\n",
    "                        if k_new >= len(n_kv):\n",
    "                            n_k = np.resize(n_k, k_new + 1)\n",
    "                            m_k = np.resize(m_k, k_new + 1)\n",
    "                            n_kv.append(None)\n",
    "                        assert k_new == using_k[-1] + 1\n",
    "                        assert k_new < len(n_kv)\n",
    "    \n",
    "                    using_k.insert(k_new, k_new)\n",
    "                    n_k[k_new] = beta * V\n",
    "                    m_k[k_new] = 0\n",
    "                    n_kv[k_new] = DefaultDict(beta)\n",
    "                    \n",
    "                assert k_new in using_k\n",
    "                \n",
    "                for t_new, t in enumerate(using_t[j]):\n",
    "                    if t_new != t: break\n",
    "                else:\n",
    "                    t_new = len(using_t[j])\n",
    "                    n_jt[j].resize(t_new+1)\n",
    "                    k_jt[j].resize(t_new+1)\n",
    "                    n_jtv[j].append(None)\n",
    "            \n",
    "                using_t[j].insert(t_new, t_new)\n",
    "                n_jt[j][t_new] = 0  # to make sure\n",
    "                n_jtv[j][t_new] = DefaultDict(0)\n",
    "            \n",
    "                k_jt[j][t_new] = k_new\n",
    "                \n",
    "                m_k[k_new] += 1\n",
    "                \n",
    "                m += 1\n",
    "            \n",
    "            assert t_new in using_t[j]\n",
    "            t_ji[j][i] = t_new\n",
    "            n_jt[j][t_new] += 1\n",
    "    \n",
    "            k_new = k_jt[j][t_new]\n",
    "            n_k[k_new] += 1\n",
    "    \n",
    "            v = x_ji[j][i]\n",
    "            n_kv[k_new][v] += 1\n",
    "            n_jtv[j][t_new][v] += 1\n",
    "            \n",
    "                \n",
    "    for j in range(M):\n",
    "        for t in using_t[j]:\n",
    "            if t != 0: \n",
    "                \"\"\"sampling k (dish=topic) from posterior\"\"\"\n",
    "    \n",
    "                #This makes the table leave from its dish and only the table counter decrease. The word counters (n_k and n_kv) stay.\n",
    "                \n",
    "                k = k_jt[j][t]\n",
    "                assert k > 0\n",
    "                assert m_k[k] > 0\n",
    "                \n",
    "                m_k[k] -= 1\n",
    "                m -= 1\n",
    "                if m_k[k] == 0:\n",
    "                    using_k.remove(k)\n",
    "                    k_jt[j][t] = 0\n",
    "                #\n",
    "                    \n",
    "                # sampling of k\n",
    "                p_k = calc_dish_posterior_t(j, t, n_k, n_jt, n_jtv)\n",
    "                \n",
    "                k_new = using_k[np.random.multinomial(1, p_k).argmax()]\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if k_new == 0:\n",
    "                    # Add new dish  \n",
    "                    for k_new, k in enumerate(using_k):\n",
    "                        if k_new != k: break\n",
    "                    else:\n",
    "                        k_new = len(using_k)\n",
    "                        if k_new >= len(n_kv):\n",
    "                            n_k = np.resize(n_k, k_new + 1)\n",
    "                            m_k = np.resize(m_k, k_new + 1)\n",
    "                            n_kv.append(None)\n",
    "                        assert k_new == using_k[-1] + 1\n",
    "                        assert k_new < len(n_kv)\n",
    "                \n",
    "                    using_k.insert(k_new, k_new)\n",
    "                    n_k[k_new] = beta * V\n",
    "                    m_k[k_new] = 0\n",
    "                    n_kv[k_new] = DefaultDict(beta)\n",
    "                    \n",
    "      \n",
    "                    \n",
    "                m += 1\n",
    "                m_k[k_new] += 1\n",
    "            \n",
    "                k_old = k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "                if k_new != k_old:\n",
    "                    k_jt[j][t] = k_new\n",
    "            \n",
    "                    n_jt2 = n_jt.copy()[j][t]\n",
    "                    if k_old != 0: n_k[k_old] -= n_jt2\n",
    "                    n_k[k_new] += n_jt2\n",
    "                    for v, n in n_jtv[j][t].items():\n",
    "                        if k_old != 0: n_kv[k_old][v] -= n\n",
    "                        n_kv[k_new][v] += n\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity Checks ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sum of the words among all the tables in doc 0 equals the sum of the words in doc 0\n",
    "sum(n_jt[0]) == len(x_ji[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 17, 2, 15, 1, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_jtv[0] (0 indexes first doc) is a list of dictionaries with each dictionary item giving the vocab index at a given table -- dict.keys() gives vocab index and dict.values() gives count \n",
    "# of that term at the table \n",
    "\n",
    "# This is the sum of words at the tables of doc 0.  It should be the same as n_jt[0][1:]\n",
    "[j for j in [sum(i.values()) for i in n_jtv[0] if i is not None] if j != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j for j in [sum(i.values()) for i in n_jtv[0] if i is not None] if j != 0] == [h for h in n_jt[0] if h != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3783"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the total number of tables (m_k is the distribution of tables across the 26 topics)\n",
    "sum(m_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3782"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is also the total number of tables.  n_jt is the number of words at each table of each document.  This should be the same as sum(m_k) but it's off by 1 for some reason\n",
    "sum([len(g) for g in [[j for j in i if j!=0] for i in n_jt]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Work Space ##### --- this can be deleted \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_dish_posterior_t(j, t):\n",
    "    \"calculate dish(topic) posterior when one table is removed\"\n",
    "    k_old = k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "    \n",
    "    Vbeta = V * beta\n",
    "    n_k = n_k.copy()\n",
    "    n_jt = n_jt[j][t]\n",
    "    n_k[k_old] -= n_jt\n",
    "    n_k = n_k[using_k]\n",
    "    log_p_k = np.log(m_k[using_k]) + gammaln(n_k) - gammaln(n_k + n_jt)\n",
    "    log_p_k_new = np.log(gamma) + gammaln(Vbeta) - gammaln(Vbeta + n_jt)\n",
    "\n",
    "    gammaln_beta = gammaln(beta)\n",
    "    for w, n_jtw in n_jtv[j][t].items():\n",
    "        assert n_jtw >= 0\n",
    "        if n_jtw == 0: continue\n",
    "        n_kw = np.array([n.get(w, beta) for n in n_kv])\n",
    "        n_kw[k_old] -= n_jtw\n",
    "        n_kw = n_kw[using_k]\n",
    "        n_kw[0] = 1 # dummy for logarithm's warning\n",
    "        if np.any(n_kw <= 0): print(n_kw) # for debug\n",
    "        log_p_k += gammaln(n_kw + n_jtw) - gammaln(n_kw)\n",
    "        log_p_k_new += gammaln(beta + n_jtw) - gammaln_beta\n",
    "        \n",
    "        \n",
    "    log_p_k[0] = log_p_k_new\n",
    "    \n",
    "    p_k = np.exp(log_p_k - log_p_k.max())\n",
    "    return p_k / p_k.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# leave_from_table - arguments: doc index / term index - this function adjusts counts (decrement by 1) for doc j, term i, table t, topic k // table is removed if needed \n",
    "def leave_from_table(j, i):\n",
    "    \n",
    "    # Store table index of a given document and term as t\n",
    "    t = t_ji[j][i]\n",
    "    \n",
    "    # If t>0 (i.e. reassigning from existing table)\n",
    "    if t  > 0:\n",
    "        # Set topic for that table to k\n",
    "        k = k_jt[j][t]\n",
    "        assert k > 0\n",
    "\n",
    "        # Store term index for given doc as v\n",
    "        v = x_ji[j][i]\n",
    "        \n",
    "        # Decrease counters - number of terms assigned to k for vocab v decreased by 1 / number of terms assigned to k decreased by 1\n",
    "        n_kv[k][v] -= 1\n",
    "        n_k[k] -= 1\n",
    "        \n",
    "        # Decrease counters - number of terms in doc j at table t decreased by 1 / term of terms in doc j at table t for vocab v decreased by 1\n",
    "        n_jt[j][t] -= 1\n",
    "        n_jtv[j][t][v] -= 1\n",
    "        \n",
    "        # If number of terms assigned to table t is now 0 remove the table \n",
    "        if n_jt[j][t] == 0:\n",
    "            remove_table(j, t)\n",
    "            \n",
    "# Remove the table when all terms are gone - arguments: doc index / table index\n",
    "def remove_table(j, t):\n",
    "    \n",
    "    # Set topic index at doc j and table t to k\n",
    "    k = k_jt[j][t]\n",
    "    \n",
    "    # Remove t from list of tables being used in doc j\n",
    "    using_t[j].remove(t)\n",
    "    \n",
    "    # Decrease number of tables for topic k by 1\n",
    "    m_k[k] -= 1\n",
    "    # Decrease number of tables overall (?) by 1\n",
    "    m -= 1\n",
    "    assert m_k[k] >= 0\n",
    "    \n",
    "    # If number of tables for topic k is 0 remove topic\n",
    "    if m_k[k] == 0:\n",
    "        using_k.remove(k)\n",
    "        \n",
    "        \n",
    "        \n",
    "# Assign guest x_ji to a new table and draw topic (dish) of the table\n",
    "#def add_new_table(j, k_new, using_t, using_k, n_jt, k_jt, n_jtv, m_k, m):\n",
    "#    assert k_new in using_k\n",
    "#    for t_new, t in enumerate(using_t[j]):\n",
    "#        if t_new != t: break\n",
    "#    else:\n",
    "#        t_new = len(using_t[j])\n",
    "#        n_jt[j].resize(t_new+1)\n",
    "#        k_jt[j].resize(t_new+1)\n",
    "#        n_jtv[j].append(None)\n",
    "#\n",
    "#    using_t[j].insert(t_new, t_new)\n",
    "#    n_jt[j][t_new] = 0  # to make sure\n",
    "#    n_jtv[j][t_new] = DefaultDict(0)\n",
    "#\n",
    "#    k_jt[j][t_new] = k_new\n",
    "#    m_k[k_new] += 1\n",
    "#    m += 1\n",
    "#\n",
    "#    return t_new\n",
    "\n",
    "\n",
    "#def seat_at_table(j, i, t_new):\n",
    "#    \n",
    "#    assert t_new in using_t[j]\n",
    "#    \n",
    "#    t_ji[j][i] = t_new\n",
    "#    n_jt[j][t_new] += 1\n",
    "#\n",
    "#    k_new = k_jt[j][t_new]\n",
    "#    n_k[k_new] += 1\n",
    "#\n",
    "#    v = x_ji[j][i]\n",
    "#    n_kv[k_new][v] += 1\n",
    "#    n_jtv[j][t_new][v] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## These are functions that still need to be annotated \n",
    "\n",
    "def seat_at_table(j, i, t_new):\n",
    "    \n",
    "    assert t_new in using_t[j]\n",
    "    \n",
    "    t_ji[j][i] = t_new\n",
    "    n_jt[j][t_new] += 1\n",
    "\n",
    "    k_new = k_jt[j][t_new]\n",
    "    n_k[k_new] += 1\n",
    "\n",
    "    v = x_ji[j][i]\n",
    "    n_kv[k_new][v] += 1\n",
    "    n_jtv[j][t_new][v] += 1\n",
    "\n",
    "# Assign guest x_ji to a new table and draw topic (dish) of the table\n",
    "def add_new_table(j, k_new):\n",
    "    assert k_new in using_k\n",
    "    for t_new, t in enumerate(using_t[j]):\n",
    "        if t_new != t: break\n",
    "    else:\n",
    "        t_new = len(using_t[j])\n",
    "        n_jt[j].resize(t_new+1)\n",
    "        k_jt[j].resize(t_new+1)\n",
    "        n_jtv[j].append(None)\n",
    "\n",
    "    using_t[j].insert(t_new, t_new)\n",
    "    n_jt[j][t_new] = 0  # to make sure\n",
    "    n_jtv[j][t_new] = DefaultDict(0)\n",
    "\n",
    "    k_jt[j][t_new] = k_new\n",
    "    m_k[k_new] += 1\n",
    "    m += 1\n",
    "\n",
    "    return t_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sampling_k(j, t):\n",
    "    \"\"\"sampling k (dish=topic) from posterior\"\"\"\n",
    "    leave_from_dish(j, t)\n",
    "\n",
    "    # sampling of k\n",
    "    p_k = calc_dish_posterior_t(j, t)\n",
    "    k_new = using_k[np.random.multinomial(1, p_k).argmax()]\n",
    "    if k_new == 0:\n",
    "        k_new = add_new_dish()\n",
    "\n",
    "    seat_at_dish(j, t, k_new)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def leave_from_dish(self, j, t):\n",
    "    \"\"\"\n",
    "    This makes the table leave from its dish and only the table counter decrease.\n",
    "    The word counters (n_k and n_kv) stay.\n",
    "    \"\"\"\n",
    "    k = k_jt[j][t]\n",
    "    assert k > 0\n",
    "    assert m_k[k] > 0\n",
    "    \n",
    "    m_k[k] -= 1\n",
    "    m -= 1\n",
    "    if m_k[k] == 0:\n",
    "        using_k.remove(k)\n",
    "        k_jt[j][t] = 0\n",
    "\n",
    "        \n",
    "        \n",
    "def calc_dish_posterior_t(j, t, n_k, n_jt, k_jt, n_jtv, n_jtw, n_kw, V, beta, using_k):\n",
    "    \"calculate dish(topic) posterior when one table is removed\"\n",
    "    k_old = k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "    \n",
    "    Vbeta = V * beta\n",
    "    n_k = n_k.copy()\n",
    "    n_jt = n_jt[j][t]\n",
    "    n_k[k_old] -= n_jt\n",
    "    n_k = n_k[using_k]\n",
    "    log_p_k = np.log(m_k[using_k]) + gammaln(n_k) - gammaln(n_k + n_jt)\n",
    "    log_p_k_new = np.log(gamma) + gammaln(Vbeta) - gammaln(Vbeta + n_jt)\n",
    "    \n",
    "    gammaln_beta = gammaln(beta)\n",
    "    \n",
    "    for w, n_jtw in n_jtv[j][t].items():\n",
    "        assert n_jtw >= 0\n",
    "        if n_jtw == 0: continue\n",
    "        n_kw = np.array([n.get(w, beta) for n in n_kv])\n",
    "        n_kw[k_old] -= n_jtw\n",
    "        n_kw = n_kw[using_k]\n",
    "        n_kw[0] = 1 # dummy for logarithm's warning\n",
    "        if np.any(n_kw <= 0): print(n_kw) # for debug\n",
    "        log_p_k += gammaln(n_kw + n_jtw) - gammaln(n_kw)\n",
    "        log_p_k_new += gammaln(beta + n_jtw) - gammaln_beta\n",
    "        \n",
    "    log_p_k[0] = log_p_k_new\n",
    "    \n",
    "    p_k = np.exp(log_p_k - log_p_k.max())\n",
    "    return p_k / p_k.sum()\n",
    "\n",
    "\n",
    "def seat_at_dish(j, t, k_new):\n",
    "    m += 1\n",
    "    m_k[k_new] += 1\n",
    "\n",
    "    k_old = k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "    if k_new != k_old:\n",
    "        k_jt[j][t] = k_new\n",
    "\n",
    "        n_jt = n_jt[j][t]\n",
    "        if k_old != 0: n_k[k_old] -= n_jt\n",
    "        n_k[k_new] += n_jt\n",
    "        for v, n in n_jtv[j][t].items():\n",
    "            if k_old != 0: n_kv[k_old][v] -= n\n",
    "            n_kv[k_new][v] += n\n",
    "\n",
    "\n",
    "def add_new_dish():\n",
    "    \"This is commonly used by sampling_t and sampling_k.\"\n",
    "    for k_new, k in enumerate(using_k):\n",
    "        if k_new != k: break\n",
    "    else:\n",
    "        k_new = len(using_k)\n",
    "        if k_new >= len(n_kv):\n",
    "            n_k = numpy.resize(n_k, k_new + 1)\n",
    "            m_k = numpy.resize(m_k, k_new + 1)\n",
    "            n_kv.append(None)\n",
    "        assert k_new == using_k[-1] + 1\n",
    "        assert k_new < len(n_kv)\n",
    "\n",
    "    using_k.insert(k_new, k_new)\n",
    "    n_k[k_new] = beta * V\n",
    "    m_k[k_new] = 0\n",
    "    n_kv[k_new] = DefaultDict(beta)\n",
    "    return k_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
